"""
Revised syn_seq.py

This module implements a sequential synthesizer (Syn_Seq) that fits each column 
of the data (following an ordering provided in syn_order) one by one.
It supports columns with special values. For such columns, during fitting the 
model only sees rows with numeric (non‐special) values. At generation time, the 
pre‐generated special indicator (“_cat”) column (injected by the preprocessor) is 
used to decide which rows should be generated by the fitted model (when the _cat 
cell equals the numeric marker) and which rows should directly receive the special value.
"""

from typing import Any, Dict, List, Optional, Tuple
import numpy as np
import pandas as pd
import warnings

# Import column-fitting and generation functions for various methods.
from synthcity.plugins.core.models.syn_seq.methods import (
    syn_cart, generate_cart,
    syn_ctree, generate_ctree,
    syn_logreg, generate_logreg,
    syn_norm, generate_norm,
    syn_pmm, generate_pmm,
    syn_polyreg, generate_polyreg,
    syn_rf, generate_rf,
    syn_lognorm, generate_lognorm,
    syn_random, generate_random,
    syn_swr, generate_swr,
)

# Map method names to (fitting function, generation function)
METHOD_MAP: Dict[str, Tuple[Any, Any]] = {
    "cart": (syn_cart, generate_cart),
    "ctree": (syn_ctree, generate_ctree),
    "logreg": (syn_logreg, generate_logreg),
    "norm": (syn_norm, generate_norm),
    "pmm": (syn_pmm, generate_pmm),
    "polyreg": (syn_polyreg, generate_polyreg),
    "rf": (syn_rf, generate_rf),
    "lognorm": (syn_lognorm, generate_lognorm),
    "random": (syn_random, generate_random),
    "swr": (syn_swr, generate_swr),
}

# --- Marker constants (changeable if needed) ---
DEFAULT_NUMERIC_MARKER = -777777777.0   # Indicates that the value is a “normal” (numeric) value
DEFAULT_MISSING_MARKER = -999999999.0     # Indicates that the original cell was missing

class Syn_Seq:
    def __init__(
        self,
        random_state: int = 0,
        sampling_patience: int = 100
    ):
        """
        Args:
            random_state: Random seed.
            sampling_patience: Maximum number of attempts in generation.
        """
        self.random_state = random_state
        self.sampling_patience = sampling_patience

        # special_values: mapping base column name -> list of special values (e.g. { "capital-gain": [0] })
        self.special_values: Dict[str, List[Any]] = {}
        # cat_distributions: for each column with a _cat indicator, store its distribution from training.
        self.cat_distributions: Dict[str, Dict[Any, float]] = {}

        self._model_trained = False

        self._syn_order: List[str] = []       # synthesis order of columns
        self._method_map: Dict[str, str] = {}   # method for each column (e.g. "cart")
        self._varsel: Dict[str, List[str]] = {} # predictors for synthesizing each column
        self._col_models: Dict[str, Dict[str, Any]] = {}  # fitted model for each column

        # For the first column, store its observed (real) distribution.
        self._first_col_distribution: Dict[str, np.ndarray] = {}

    def fit_col(self, loader: Any, *args: Any, **kwargs: Any) -> "Syn_Seq":
        """
        Fit each column sequentially using metadata from the loader.
        Also extracts special values from any _cat columns and computes the training 
        distribution of those columns.
        """
        info_dict = loader.info()
        training_data = loader.dataframe().copy()
        if training_data.empty:
            raise ValueError("No data => cannot fit Syn_Seq aggregator")

        # Set synthesis order, method mapping, and variable selection from loader info.
        self._syn_order = info_dict.get("syn_order", list(training_data.columns))
        self._method_map = info_dict.get("method", {})
        self._varsel = info_dict.get("variable_selection", {})

        # --- Extract special values and _cat column distributions from the training data ---
        for col in training_data.columns:
            if col.endswith("_cat"):
                base_col = col[:-4]
                # Extract all unique values except the numeric and missing markers
                specials = training_data[col].unique().tolist()
                specials = [v for v in specials if v != DEFAULT_NUMERIC_MARKER and v != DEFAULT_MISSING_MARKER]
                if specials:
                    self.special_values[base_col] = specials
                valid = training_data[col].dropna()
                if len(valid) > 0:
                    self.cat_distributions[base_col] = valid.value_counts(normalize=True).to_dict()
                else:
                    self.cat_distributions[base_col] = {DEFAULT_NUMERIC_MARKER: 1.0}

        # For auto-injected _cat columns, force method "cart" and mirror variable selection.
        for col in self._syn_order:
            if col.endswith("_cat"):
                self._method_map[col] = "cart"
                base_col = col[:-4]
                if base_col in self._varsel:
                    self._varsel[col] = self._varsel[base_col]
                else:
                    idx = self._syn_order.index(col)
                    self._varsel[col] = self._syn_order[:idx]

        print("[INFO] Syn_Seq aggregator: fitting columns...")

        # (1) For the first column, store its observed (non-null) distribution.
        first_col = self._syn_order[0]
        self._first_col_distribution[first_col] = training_data[first_col].dropna().values

        # (2) For columns with special values, store only rows that are not special.
        for col, specials in self.special_values.items():
            if col not in training_data.columns:
                continue
            filtered = training_data[~training_data[col].isin(specials)]
            self._first_col_distribution[col] = filtered[col].dropna().values

        print(f"Fitting '{first_col}' => stored distribution from real data. Done.")

        # (3) Fit a model for each subsequent column.
        np.random.seed(self.random_state)
        for i, col in enumerate(self._syn_order[1:], start=1):
            method_name = self._method_map.get(col, "cart")
            preds_list = self._varsel.get(col, self._syn_order[:i])
            y = training_data[col].values
            X = training_data[preds_list].values
            mask = ~pd.isna(y)
            # For numeric columns with special values, drop rows whose value is special.
            if col in self.special_values:
                specials = self.special_values[col]
                mask = mask & (~np.isin(y, specials))
            X_ = X[mask]
            y_ = y[mask]
            print(f"Fitting '{col}' with '{method_name}' ... ", end="", flush=True)
            try:
                self._col_models[col] = self._fit_single_col(method_name, X_, y_)
            except Exception as e:
                print(f"Error fitting column {col}: {e}. Falling back to swr.", end=" ")
                try:
                    self._col_models[col] = self._fit_single_col("swr", X, y)
                except Exception as e2:
                    print(f"Fallback swr also failed for {col}: {e2}. Storing None.", end=" ")
                    self._col_models[col] = None
            print("Done!")
        self._model_trained = True
        return self

    def _fit_single_col(self, method_name: str, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
        """
        Fit a single column using the specified method.
        """
        fit_func, _ = METHOD_MAP[method_name]
        model = fit_func(y, X, random_state=self.random_state)
        return {"name": method_name, "fitted_model": model}

    def generate_col(self, count: int) -> pd.DataFrame:
        """
        Generate `count` rows sequentially.
        
        For columns with special values, the pre‐generated numeric indicator (“_cat”) column 
        is used to decide which rows should have their value generated using the fitted model 
        (if the _cat cell equals the DEFAULT_NUMERIC_MARKER) and which rows should directly 
        receive the special value.
        If the generated _cat column contains no DEFAULT_NUMERIC_MARKER flag, it is re‐sampled 
        using the stored training distribution.
        """
        if not self._model_trained:
            raise RuntimeError("Syn_Seq aggregator not yet fitted")
        if count <= 0:
            return pd.DataFrame(columns=self._syn_order)
        
        # Initialize a DataFrame with NaN values for all columns.
        gen_df = pd.DataFrame({col: [np.nan] * count for col in self._syn_order})
        
        # (1) Generate the first column using its stored distribution.
        first_col = self._syn_order[0]
        if (first_col in self._first_col_distribution and 
            len(self._first_col_distribution[first_col]) > 0):
            gen_df[first_col] = np.random.choice(
                self._first_col_distribution[first_col], size=count, replace=True
            )
        else:
            gen_df[first_col] = 0
        print(f"Generating '{first_col}' => done.")
        
        # (2) For each subsequent column, generate synthetic values.
        for col in self._syn_order[1:]:
            method_name = self._method_map.get(col, "cart")
            preds_list = self._varsel.get(col, self._syn_order[:self._syn_order.index(col)])
            
            # Check if the column has a corresponding _cat indicator.
            cat_col = col + "_cat"
            if col in self.special_values and cat_col in gen_df.columns:
                # Check if the generated _cat column has any numeric marker.
                numeric_count = (gen_df[cat_col] == DEFAULT_NUMERIC_MARKER).sum()
                if numeric_count == 0:
                    warnings.warn(
                        f"Degenerate _cat column for {col}: no rows marked as numeric. Re-sampling _cat column using training distribution."
                    )
                    cat_dist = self.cat_distributions.get(col, {DEFAULT_NUMERIC_MARKER: 1.0})
                    total = sum(cat_dist.values())
                    cat_probs = {k: v / total for k, v in cat_dist.items()}
                    new_cat = np.where(
                        np.random.rand(count) < cat_probs.get(DEFAULT_NUMERIC_MARKER, 1.0),
                        float(DEFAULT_NUMERIC_MARKER),
                        np.random.choice(
                            [k for k in cat_probs if k != DEFAULT_NUMERIC_MARKER],
                            size=count,
                            p=[cat_probs[k] for k in cat_probs if k != DEFAULT_NUMERIC_MARKER]
                        )
                    )
                    gen_df[cat_col] = new_cat
                gen_df[cat_col] = gen_df[cat_col].astype(float)

                # For rows with _cat equal to the numeric marker, generate synthetic values.
                is_numeric = gen_df[cat_col] == DEFAULT_NUMERIC_MARKER
                if is_numeric.sum() > 0:
                    Xsyn_numeric = gen_df.loc[is_numeric, preds_list].values
                    ysyn_numeric = self._generate_single_col(method_name, Xsyn_numeric, col)
                    gen_df.loc[is_numeric, col] = ysyn_numeric
                # For rows where _cat equals a special value, assign that special value directly.
                for special in self.special_values[col]:
                    is_special = gen_df[cat_col] == special
                    gen_df.loc[is_special, col] = special
            else:
                # Otherwise, generate the column normally.
                Xsyn = gen_df[preds_list].values
                ysyn = self._generate_single_col(method_name, Xsyn, col)
                gen_df[col] = ysyn
            print(f"Generating '{col}' => done.")
        return gen_df

    def _generate_single_col(self, method_name: str, Xsyn: np.ndarray, col: str) -> np.ndarray:
        """
        Generate synthetic values for a single column using the fitted model.
        If no model is available for the column, a RuntimeError is raised.
        """
        if col not in self._col_models or self._col_models[col] is None:
            raise RuntimeError(f"No model available for column {col}.")
        fit_info = self._col_models[col]
        _, generate_func = METHOD_MAP[fit_info["name"]]
        return generate_func(fit_info["fitted_model"], Xsyn)

